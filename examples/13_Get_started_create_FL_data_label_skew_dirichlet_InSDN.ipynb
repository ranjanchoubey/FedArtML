{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1352b66",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ranjanchoubey/FedArtML/blob/main/examples/13_Get_started_create_FL_data_label_skew_dirichlet_InSDN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db1bb9",
   "metadata": {},
   "source": [
    "# Getting started with FedArtML creating FL data (label skew) and implementing an FL model\n",
    "\n",
    "Our ***FedArTML*** tool facilitates the generation of non-IID datasets\n",
    "in a controlled way to support federated learning (FL) research for federated datasets from centralized datasets. It includes classes and functions to create federated datasets from centralized data, given the **number** of **clients** and the degree of heterogeneity (**non-IID-ness**) desired.\n",
    "\n",
    "This guide aims to **understand** using the **SplitAsFederatedData** class to create federated datasets with the **Dirichlet method** for **Label skew**. We use the `InSDN` dataset for our tests. Moreover, we include the `Flower framework` to train an FL model using the output from the FedArtML library.\n",
    "\n",
    "**Notes:**\n",
    "1. To check the source code, you can visit the [GitHub repo](https://github.com/Sapienza-University-Rome/FedArtML)\n",
    "2. To check the documentation, you visit the [dedicated link](https://fedartml.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b6641",
   "metadata": {},
   "source": [
    "# Install libraries\n",
    "\n",
    "First, installing the FedArtML and Flower libraries from Pypi (the latest version) is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545d1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install FedArtML Library { display-mode: \"form\" }\n",
    "!pip install -q fedartml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c833f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install Flower Framework { display-mode: \"form\" }\n",
    "!pip install -q flwr[simulation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6b91c",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import Libraries & Configure Environment { display-mode: \"form\" }\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", rc = {'figure.figsize':(5,7)})\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# Garbage Collector - use it like gc.collect()\n",
    "import gc\n",
    "\n",
    "# Custom Callback To Include in Callbacks List At Training Time\n",
    "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        gc.collect()\n",
    "\n",
    "from fedartml import InteractivePlots, SplitAsFederatedData\n",
    "\n",
    "# Make TensorFlow logs less verbose\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import flwr as fl\n",
    "\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from flwr.common import Metrics\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1f140",
   "metadata": {},
   "source": [
    "# Define parameters\n",
    "\n",
    "Then it is necessary to define some parameters to run this notebook smoothly. The most important are:\n",
    "\n",
    "\n",
    "\n",
    "*   `local_nodes_glob`: Defines the desired number of clients (local nodes) the centralized data will be divided into. In this case, we set it as 3.\n",
    "*   `Alpha`: Using the \"Dirichlet-based\" method, we need to define the `Alpha`, which will determine the degree of heterogeneity of the client's distribution (non-IID-ness). Notice that the smaller the value of `Alpha`, the higher the non-IID-ness. In this case, we set it as 1. Those parameters can be changed if desired to get familiar with their use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b54f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Initialization { display-mode: \"form\" }\n",
    "\n",
    "# Define random state for reproducibility\n",
    "random_state = 0  # @param {type: \"integer\", min: 0, max: 10000, step: 1}\n",
    "\n",
    "# Define colors to use in plots\n",
    "colors = [\"#00cfcc\",\"#e6013b\",\"#007f88\",\"#00cccd\",\"#69e0da\",\"darkblue\",\"#FFFFFF\"]\n",
    "\n",
    "# Path to InSDN dataset\n",
    "dataset_path = '../data/LINK_all_features_all_datsets/InSDN'\n",
    "\n",
    "print(\"\\n✓ Initialization complete. Load data and then configure federated learning parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07409718",
   "metadata": {},
   "source": [
    "# Define functions\n",
    "\n",
    "For the sake of order, we defined some functions that will be used in this guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define Helper Functions { display-mode: \"form\" }\n",
    "\n",
    "# Define function to test a model and retrieve classification metrics\n",
    "def test_model(model, X_test, Y_test):\n",
    "    cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False)\n",
    "    logits = model.predict(X_test, batch_size=32, verbose=1, callbacks=[GarbageCollectorCallback()])\n",
    "    y_pred = tf.argmax(logits, axis=1)\n",
    "    loss = cce(Y_test, logits).numpy()\n",
    "    acc = accuracy_score(y_pred, Y_test)\n",
    "    pre = precision_score(y_pred, Y_test, average='weighted',zero_division = 0)\n",
    "    rec = recall_score(y_pred, Y_test, average='weighted',zero_division = 0)\n",
    "    f1s = f1_score(y_pred, Y_test, average='weighted',zero_division = 0)\n",
    "\n",
    "    return loss, acc, pre, rec, f1s\n",
    "\n",
    "# Define function to convert from SplitAsFederatedData function output (FedArtML) to Flower (list) format\n",
    "def from_FedArtML_to_Flower_format(clients_dict):\n",
    "  # initialize list that contains clients (features and labels) to extract later from client_fn in Flower\n",
    "  list_x_train = []\n",
    "  list_y_train = []\n",
    "\n",
    "  # Get the name of the clients from the dictionary\n",
    "  client_names = list(clients_dict.keys())\n",
    "\n",
    "  # Iterate over each client\n",
    "  for client in client_names:\n",
    "    # Get data from each client\n",
    "    each_client_train=np.array(clients_dict[client],dtype=object)\n",
    "\n",
    "    # Extract features for each client\n",
    "    feat=[]\n",
    "    x_tra=np.array(each_client_train[:, 0])\n",
    "    for row in x_tra:\n",
    "      feat.append(row)\n",
    "    feat=np.array(feat)\n",
    "\n",
    "    # Extract labels from each client\n",
    "    y_tra=np.array(each_client_train[:, 1])\n",
    "\n",
    "    # Append in list features and labels to extract later from client_fn in Flower\n",
    "    list_x_train.append(feat)\n",
    "    list_y_train.append(y_tra)\n",
    "\n",
    "  return list_x_train, list_y_train\n",
    "\n",
    "# Define Dense Neural Network (DNN) model for tabular InSDN data\n",
    "def DNN_model(input_shape, num_classes):\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Input(shape=(input_shape,)))\n",
    "  model.add(layers.Dense(128, activation='relu'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "  model.add(layers.Dense(64, activation='relu'))\n",
    "  model.add(layers.BatchNormalization())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "  model.add(layers.Dense(32, activation='relu'))\n",
    "  model.add(layers.Dropout(0.2))\n",
    "  model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "# Define local training/evaluation function\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, x_train, y_train, x_test, y_test, epochs_client) -> None:\n",
    "        self.model = model\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test\n",
    "        self.epochs_client = epochs_client\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        self.model.fit(self.x_train, self.y_train, validation_split=0.1, epochs=self.epochs_client, verbose=2)\n",
    "        return self.model.get_weights(), len(self.x_train), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        loss, acc = self.model.evaluate(self.x_test, self.y_test, verbose=2)\n",
    "        return loss, len(self.x_test), {\"accuracy\": acc}\n",
    "\n",
    "def plot_metric_from_history(\n",
    "    hist: None,\n",
    "    save_plot_path: None,\n",
    "    metric_type: None,\n",
    "    metric: None,\n",
    ") -> None:\n",
    "    \"\"\"Function to plot from Flower server History.\n",
    "    Parameters\n",
    "    ----------\n",
    "    hist : History\n",
    "        Object containing evaluation for all rounds.\n",
    "    save_plot_path : Path\n",
    "        Folder to save the plot to.\n",
    "    metric_type : Literal[\"centralized\", \"distributed\"]\n",
    "        Type of metric to plot.\n",
    "    metric : Literal[\"accuracy\",\"precision\",\"recall\",\"f1score\"]\n",
    "        Metric to plot.\n",
    "    \"\"\"\n",
    "    metric_dict = (\n",
    "        hist.metrics_centralized\n",
    "        if metric_type == \"centralized\"\n",
    "        else hist.metrics_distributed\n",
    "    )\n",
    "    rounds, values = zip(*metric_dict[metric])\n",
    "    # plt.plot(np.asarray(rounds), np.asarray(values), label=\"FedAvg\")\n",
    "    plt.plot(np.asarray(rounds), np.asarray(values), color=colors[5], linewidth=5, label='Test')\n",
    "    plt.legend(fontsize=45)\n",
    "    plt.xlabel('Communication round', fontsize=40)\n",
    "    plt.ylabel(metric, fontsize=50)\n",
    "    plt.title(metric, fontsize=60)\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    # plt.ylim(min(min(min(commun_metrics))) - 0.05, max(max(max(commun_metrics))) + 0.05)\n",
    "    plt.ylim(0, 1)\n",
    "    # plt.savefig(Path(save_plot_path) / Path(f\"{metric_type}_metrics{suffix}.png\"))\n",
    "    # plt.close()\n",
    "\n",
    "def retrieve_global_metrics(\n",
    "    hist: None,\n",
    "    metric_type: None,\n",
    "    metric: None,\n",
    "    best_metric: None,\n",
    ") -> None:\n",
    "    \"\"\"Function to retrieve metrics from Flower server History.\n",
    "    Parameters\n",
    "    ----------\n",
    "    hist : History\n",
    "        Object containing evaluation for all rounds.\n",
    "    metric_type : Literal[\"centralized\", \"distributed\"]\n",
    "        Type of metric to retrieve.\n",
    "    metric : Literal[\"accuracy\",\"precision\",\"recall\",\"f1score\"]\n",
    "        Metric to retrieve.\n",
    "    \"\"\"\n",
    "    metric_dict = (\n",
    "        hist.metrics_centralized\n",
    "        if metric_type == \"centralized\"\n",
    "        else hist.metrics_distributed\n",
    "    )\n",
    "    rounds, values = zip(*metric_dict[metric])\n",
    "    if best_metric:\n",
    "      metric_return = max(values)\n",
    "    else:\n",
    "      metric_return = values[-1]\n",
    "    return metric_return\n",
    "\n",
    "print(\"✓ All helper functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51599bbd",
   "metadata": {},
   "source": [
    "# Load and preprocess InSDN data\n",
    "\n",
    "The InSDN dataset consists of network traffic data with various features. We will load, preprocess, and split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd6fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Load InSDN Dataset from Official Source { display-mode: \"form\" }\n",
    "\n",
    "# Load InSDN dataset from official UCD source\n",
    "# InSDN: SDN Intrusion Detection Dataset\n",
    "# Source: https://aseados.ucd.ie/datasets/SDN/\n",
    "# Paper: \"InSDN: SDN Intrusion Dataset\" IEEE Access Vol.8, pp 165263-165284, Sep 2020\n",
    "\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "print(\"Loading InSDN dataset...\")\n",
    "print(\"Dataset Information:\")\n",
    "print(\"  - Total instances: 343,939 network flow records\")\n",
    "print(\"  - Normal traffic: 68,424 (20%)\")\n",
    "print(\"  - Attack traffic: 275,515 (80%)\")\n",
    "print(\"  - Features: 80+ network flow characteristics\")\n",
    "print(\"  - Attack types: DoS, DDoS, Probe, Brute Force, Exploitation, Web Attack, Botnet\")\n",
    "\n",
    "df = None\n",
    "\n",
    "# Option 1: Try to load from local path first\n",
    "try:\n",
    "    if os.path.exists(dataset_path):\n",
    "        data_files = [f for f in os.listdir(dataset_path) if f.endswith('.csv')]\n",
    "        if data_files:\n",
    "            print(f\"\\n✓ Found local dataset: {data_files[0]}\")\n",
    "            df = pd.read_csv(os.path.join(dataset_path, data_files[0]))\n",
    "except Exception as e:\n",
    "    print(f\"Local path check failed: {e}\")\n",
    "\n",
    "# Option 2: Download from official UCD source\n",
    "if df is None:\n",
    "    try:\n",
    "        print(\"\\n✓ Attempting to download official InSDN dataset from UCD...\")\n",
    "        zip_url = \"https://aseados.ucd.ie/datasets/SDN/InSDN_DatasetCSV.zip\"\n",
    "        \n",
    "        response = requests.get(zip_url, timeout=30)\n",
    "        if response.status_code == 200:\n",
    "            print(\"  Download successful! Extracting dataset...\")\n",
    "            \n",
    "            # Extract and load the zip file\n",
    "            zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "            csv_files = [f for f in zip_file.namelist() if f.endswith('.csv')]\n",
    "            \n",
    "            if csv_files:\n",
    "                # Prefer OVS.csv for more attack variety\n",
    "                selected_file = next((f for f in csv_files if 'OVS.csv' in f), csv_files[0])\n",
    "                print(f\"  Loading: {selected_file}\")\n",
    "                df = pd.read_csv(zip_file.open(selected_file))\n",
    "                print(f\"✓ Successfully loaded InSDN dataset! Shape: {df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {e}\")\n",
    "\n",
    "# If download fails, provide instructions\n",
    "if df is None or df.empty:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Could not load dataset automatically\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nPlease download manually from:\")\n",
    "    print(\"  https://aseados.ucd.ie/datasets/SDN/\")\n",
    "    print(\"\\nSteps:\")\n",
    "    print(\"  1. Download: InSDN_DatasetCSV.zip\")\n",
    "    print(\"  2. Extract the ZIP file\")\n",
    "    print(\"  3. Choose one CSV file:\")\n",
    "    print(\"     - OVS.csv (136,743 records - recommended for variety)\")\n",
    "    print(\"     - metasploitable-2.csv (138,772 records)\")\n",
    "    print(\"     - Normal_data.csv (68,424 records - benign traffic only)\")\n",
    "    print(f\"  4. Place in: {os.path.abspath(dataset_path)}\")\n",
    "    print(\"=\"*80)\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# Display dataset information\n",
    "if not df.empty:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"InSDN Dataset Loaded Successfully!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Shape: {df.shape[0]} records x {df.shape[1]} features\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nColumn names ({len(df.columns)} total):\")\n",
    "    print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Preprocess InSDN Data { display-mode: \"form\" }\n",
    "\n",
    "# Preprocess InSDN data\n",
    "if not df.empty:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Preprocessing InSDN Data\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nDataFrame shape: {df.shape}\")\n",
    "    print(f\"Column names (first 10): {list(df.columns[:10])}\")\n",
    "    \n",
    "    # The InSDN dataset has 'Label' column (uppercase L)\n",
    "    if 'Label' in df.columns:\n",
    "        y_raw = df['Label'].values\n",
    "        print(f\"\\n✓ Found 'Label' column\")\n",
    "        print(f\"  Unique labels: {np.unique(y_raw)}\")\n",
    "        print(f\"  Label counts: {pd.Series(y_raw).value_counts().to_dict()}\")\n",
    "        \n",
    "        # Drop the Label column and non-numeric metadata columns\n",
    "        X_df = df.drop(columns=['Label', 'Flow ID', 'Src IP', 'Dst IP', 'Timestamp'], errors='ignore')\n",
    "    else:\n",
    "        print(\"ERROR: 'Label' column not found!\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        raise ValueError(\"'Label' column not found in dataset\")\n",
    "    \n",
    "    # Select only numeric columns for features\n",
    "    X_df = X_df.select_dtypes(include=[np.number])\n",
    "    print(f\"\\nNumeric features shape: {X_df.shape}\")\n",
    "    print(f\"Feature columns: {list(X_df.columns[:10])}... (showing first 10)\")\n",
    "    \n",
    "    X = X_df.values\n",
    "    \n",
    "    # Convert labels to numeric (they are strings like 'BFA', 'DoS', etc.)\n",
    "    unique_labels = sorted(set(y_raw))\n",
    "    label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    y = np.array([label_mapping[label] for label in y_raw]).astype(int)\n",
    "    \n",
    "    print(f\"\\nLabel mapping ({len(label_mapping)} classes):\")\n",
    "    for label, idx in label_mapping.items():\n",
    "        print(f\"  {label} -> {idx}\")\n",
    "    \n",
    "    print(f\"\\nLabel information:\")\n",
    "    print(f\"  - Unique numeric labels: {sorted(np.unique(y))}\")\n",
    "    print(f\"  - Label range: [{y.min()}, {y.max()}]\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\nOriginal class distribution:\")\n",
    "    for cls, count in zip(unique_classes, class_counts):\n",
    "        original_label = [k for k, v in label_mapping.items() if v == cls][0]\n",
    "        print(f\"  Class {cls} ({original_label}): {count} samples ({100*count/len(y):.1f}%)\")\n",
    "    \n",
    "    # Handle missing values in features\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X = imputer.fit_transform(X)\n",
    "    print(\"\\n✓ Missing values handled (mean imputation)\")\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    print(\"✓ Features normalized (StandardScaler)\")\n",
    "    \n",
    "    # Remove classes with very few samples (< 2) to avoid stratification issues\n",
    "    min_samples_per_class = 2\n",
    "    valid_classes = unique_classes[class_counts >= min_samples_per_class]\n",
    "    mask = np.isin(y, valid_classes)\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    print(f\"\\nFiltered class distribution (removed classes with < {min_samples_per_class} samples):\")\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "    for cls, count in zip(unique_classes, class_counts):\n",
    "        original_label = [k for k, v in label_mapping.items() if v == cls][0]\n",
    "        print(f\"  Class {cls} ({original_label}): {count} samples ({100*count/len(y):.1f}%)\")\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    # Use stratified split if possible, otherwise use random split\n",
    "    try:\n",
    "        x_train_glob, x_test_glob, y_train_glob, y_test_glob = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state, stratify=y\n",
    "        )\n",
    "        print(\"\\n✓ Used stratified train-test split\")\n",
    "    except ValueError:\n",
    "        # If stratification fails, use random split\n",
    "        x_train_glob, x_test_glob, y_train_glob, y_test_glob = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state, stratify=None\n",
    "        )\n",
    "        print(\"✓ Used random train-test split (stratification not possible)\")\n",
    "    \n",
    "    # Get dataset statistics\n",
    "    num_classes = len(np.unique(y_train_glob))\n",
    "    input_shape = x_train_glob.shape[1]\n",
    "    \n",
    "    print(f\"\\nDataset Statistics:\")\n",
    "    print(f\"  - Training set: {x_train_glob.shape}\")\n",
    "    print(f\"  - Test set: {x_test_glob.shape}\")\n",
    "    print(f\"  - Number of classes: {num_classes}\")\n",
    "    print(f\"  - Input shape: {input_shape}\")\n",
    "    print(f\"  - Label range (train): [{y_train_glob.min()}, {y_train_glob.max()}]\")\n",
    "    print(f\"  - Label range (test): [{y_test_glob.min()}, {y_test_glob.max()}]\")\n",
    "    print(f\"\\nClass distribution in training set:\")\n",
    "    unique, counts = np.unique(y_train_glob, return_counts=True)\n",
    "    for cls, count in zip(unique, counts):\n",
    "        pct = 100 * count / len(y_train_glob)\n",
    "        original_label = [k for k, v in label_mapping.items() if v == cls][0]\n",
    "        print(f\"    Class {cls} ({original_label}): {count} samples ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"Cannot preprocess - dataset is empty\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Visualize Class Distributions { display-mode: \"form\" }\n",
    "\n",
    "# Visualize class distributions\n",
    "if not df.empty:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Training set\n",
    "    unique_train, counts_train = np.unique(y_train_glob, return_counts=True)\n",
    "    axes[0].bar(unique_train, counts_train, color=colors[0], alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_xlabel('Label', fontsize=12)\n",
    "    axes[0].set_ylabel('Count', fontsize=12)\n",
    "    axes[0].set_title('Centralized Datatset : Training Set Label Distribution', fontsize=14)\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Test set\n",
    "    unique_test, counts_test = np.unique(y_test_glob, return_counts=True)\n",
    "    axes[1].bar(unique_test, counts_test, color=colors[1], alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_xlabel('Label', fontsize=12)\n",
    "    axes[1].set_ylabel('Count', fontsize=12)\n",
    "    axes[1].set_title('Centralized Datatset : Test Set Label Distribution', fontsize=14)\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c129b8",
   "metadata": {},
   "source": [
    "# Create the federated dataset\n",
    "\n",
    "This core function allows the creation of FL data from centralized data. The class `SplitAsFederatedData` is instantiated using a `random_state` to reproduce the results.\n",
    "\n",
    "Then, the `.create_clients` function performs the federation of the centralized data by taking the features and labels, defining the number of desired clients and setting the Alpha value.\n",
    "\n",
    "**Note:** When creating federated data and setting heterogeneous distributions (i.e. high values of percent_noniid or small values of Alpha), it is more likely the clients hold examples from only one class. Then, two cases are returned as output for fed_data and distances:\n",
    "- \"with_class_completion\": In this case, the clients are completed with one (random) example of each missing class for each client to have all the label's classes.\n",
    "- \"without_class_completion\": In this case, the clients are NOT completed with one (random) example of each missing class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff58c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title FEDERATED LEARNING CONFIGURATION: Set Parameters Here { display-mode: \"form\" }\n",
    "\n",
    "# ================================================================================\n",
    "# USER INPUT - SET THESE PARAMETERS ONLY ONCE\n",
    "# These will be used throughout the entire notebook for federated dataset creation\n",
    "# ================================================================================\n",
    "\n",
    "# Number of clients/local nodes for federated learning\n",
    "num_clients = 5  # @param {type: \"integer\", min: 2, max: 50, step: 1}\n",
    "\n",
    "# Distribution method for data heterogeneity\n",
    "distribution_method = \"dirichlet\"  # @param [\"dirichlet\", \"percent_noniid\", \"no-label-skew\"]\n",
    "\n",
    "# Heterogeneity parameter (alpha)\n",
    "# - For Dirichlet: controls concentration (smaller = more non-IID)\n",
    "# - For Percent Non-IID: converted to percentage (0-100)\n",
    "# - For IID: ignored (uniform distribution)\n",
    "alpha = 1  # @param {type: \"number\", min: 0.001, max: 10.0, step: 0.1}\n",
    "\n",
    "# Class completion strategy\n",
    "# - \"with_class_completion\": Each client gets at least one sample from all classes\n",
    "# - \"without_class_completion\": Clients may have missing classes (true non-IID scenario)\n",
    "class_completion = \"without_class_completion\"  # @param [\"with_class_completion\", \"without_class_completion\"]\n",
    "\n",
    "# ================================================================================\n",
    "# DISPLAY CONFIGURATION SUMMARY\n",
    "# ================================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEDERATED LEARNING CONFIGURATION - Ready to Create Dataset\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n  ✓ Number of Clients: {num_clients}\")\n",
    "print(f\"  ✓ Distribution Method: {distribution_method.upper()}\")\n",
    "print(f\"  ✓ Heterogeneity Parameter (alpha): {alpha}\")\n",
    "print(f\"  ✓ Class Completion: {class_completion.upper()}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"SELECTED METHOD DETAILS:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if distribution_method == \"dirichlet\":\n",
    "    print(f\"\\n  METHOD: Dirichlet Distribution (LABEL SKEW)\")\n",
    "    print(f\"  Alpha = {alpha}\")\n",
    "    print(f\"\\n  What it does:\")\n",
    "    print(f\"    • Each client receives a different subset of labels\")\n",
    "    print(f\"    • Smaller alpha → More non-IID (heterogeneous)\")\n",
    "    print(f\"    • Larger alpha → More balanced (approaching IID)\")\n",
    "\n",
    "elif distribution_method == \"percent_noniid\":\n",
    "    percent_val = max(0, min(100, (alpha / 10.0) * 100))\n",
    "    print(f\"\\n  METHOD: Percent Non-IID Distribution\")\n",
    "    print(f\"  Alpha = {alpha} (converted to {percent_val:.1f}% non-IID)\")\n",
    "    print(f\"\\n  What it does:\")\n",
    "    print(f\"    • Each client has different class distributions\")\n",
    "    print(f\"    • Based on percentage of non-IID samples\")\n",
    "\n",
    "elif distribution_method == \"no-label-skew\":\n",
    "    print(f\"\\n  METHOD: No Label Skew (IID Distribution)\")\n",
    "    print(f\"  Alpha parameter: IGNORED\")\n",
    "    print(f\"\\n  What it does:\")\n",
    "    print(f\"    • Each client gets balanced class distribution\")\n",
    "    print(f\"    • All clients have similar label proportions\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"CLASS COMPLETION STRATEGY:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if class_completion == \"with_class_completion\":\n",
    "    print(f\"\\n  ✓ WITH Class Completion\")\n",
    "    print(f\"  Each client will receive at least 1 sample from every class\")\n",
    "    print(f\"  • Ensures all classes are represented in each client\")\n",
    "    print(f\"  • Reduces data heterogeneity\")\n",
    "    print(f\"  • Useful for testing federated learning algorithms\")\n",
    "else:\n",
    "    print(f\"\\n  ✓ WITHOUT Class Completion\")\n",
    "    print(f\"  Clients may have missing classes (true non-IID scenario)\")\n",
    "    print(f\"  • Reflects real-world federated scenarios\")\n",
    "    print(f\"  • Higher data heterogeneity\")\n",
    "    print(f\"  • More challenging for federated learning\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"✓ Ready to create {num_clients} clients with:\")\n",
    "print(f\"  - Distribution: {distribution_method}\")\n",
    "print(f\"  - Class Completion: {class_completion}\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Instantiate a SplitAsFederatedData object { display-mode: \"form\" }\n",
    "if not df.empty:\n",
    "    # Instantiate a SplitAsFederatedData object\n",
    "    my_federater = SplitAsFederatedData(random_state = random_state)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CREATING FEDERATED DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Method: {distribution_method}\")\n",
    "    print(f\"Number of clients: {num_clients}\")\n",
    "    print(f\"Class Completion: {class_completion}\")\n",
    "    \n",
    "    # Create clients based on selected distribution method\n",
    "    if distribution_method == \"dirichlet\":\n",
    "        # Dirichlet: use alpha directly (0.001-10.0)\n",
    "        print(f\"Alpha: {alpha}\")\n",
    "        clients_glob_dic, list_ids_sampled_dic, miss_class_per_node, distances = my_federater.create_clients(\n",
    "            image_list = x_train_glob, \n",
    "            label_list = y_train_glob,\n",
    "            num_clients = num_clients,\n",
    "            prefix_cli='Local_node',\n",
    "            method = \"dirichlet\",\n",
    "            alpha = alpha\n",
    "        )\n",
    "        print(f\"\\n✓ Dirichlet distribution created successfully\")\n",
    "        \n",
    "    elif distribution_method == \"percent_noniid\":\n",
    "        # Percent Non-IID: convert alpha to percentage (0-100)\n",
    "        percent_value = max(0, min(100, (alpha / 10.0) * 100))\n",
    "        print(f\"Alpha: {alpha} → {percent_value:.1f}% non-IID\")\n",
    "        clients_glob_dic, list_ids_sampled_dic, miss_class_per_node, distances = my_federater.create_clients(\n",
    "            image_list = x_train_glob, \n",
    "            label_list = y_train_glob,\n",
    "            num_clients = num_clients,\n",
    "            prefix_cli='Local_node',\n",
    "            method = \"percent_noniid\",\n",
    "            alpha = percent_value\n",
    "        )\n",
    "        print(f\"\\n✓ Percent Non-IID distribution created successfully\")\n",
    "        \n",
    "    elif distribution_method == \"no-label-skew\":\n",
    "        # IID: ignore alpha (uniform distribution)\n",
    "        print(f\"Alpha: IGNORED (IID distribution)\")\n",
    "        clients_glob_dic, list_ids_sampled_dic, miss_class_per_node, distances = my_federater.create_clients(\n",
    "            image_list = x_train_glob, \n",
    "            label_list = y_train_glob,\n",
    "            num_clients = num_clients,  # USE num_clients FROM USER INPUT\n",
    "            prefix_cli='Local_node',\n",
    "            method = \"no-label-skew\",\n",
    "            alpha = None\n",
    "        )\n",
    "        print(f\"\\n✓ IID (no label skew) distribution created successfully\")\n",
    "\n",
    "    clients_glob = clients_glob_dic[class_completion]\n",
    "    list_ids_sampled = list_ids_sampled_dic[class_completion]\n",
    "\n",
    "    # Convert from SplitAsFederatedData function output (FedArtML) to Flower (list) format\n",
    "    list_x_train, list_y_train = from_FedArtML_to_Flower_format(clients_dict=clients_glob)\n",
    "    \n",
    "    print(f\"\\nFederated dataset statistics:\")\n",
    "    print(f\"  - Number of clients created: {len(list_x_train)}\")\n",
    "    print(f\"  - Training samples per client: {[len(x) for x in list_x_train]}\")\n",
    "    print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Calculate Distances { display-mode: \"form\" }\n",
    "\n",
    "if not df.empty:\n",
    "    # Calculate distances\n",
    "    JSD_glob = distances[class_completion]['jensen-shannon']\n",
    "    print(\"Jensen-Shannon distance:\", JSD_glob)\n",
    "    HD_glob = distances[class_completion]['hellinger']\n",
    "    print(\"Hellinger distance:\", HD_glob)\n",
    "\n",
    "    EMD_glob = distances[class_completion]['earth-movers']\n",
    "    print(\"Earth Mover's distance:\", EMD_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Calculate Distances { display-mode: \"form\" }\n",
    "if not df.empty:\n",
    "    # ================================================================================\n",
    "    # STANDARD COLOR PALETTE VISUALIZATION - Professional & Accessible\n",
    "    # ================================================================================\n",
    "    \n",
    "    # Use standard professional color palettes from seaborn/matplotlib\n",
    "    # These are tested, accessible, and widely used in scientific visualization\n",
    "    standard_palette = sns.color_palette(\"husl\", len(label_mapping))\n",
    "    \n",
    "    # Create mapping of labels to standard colors\n",
    "    label_to_standard_color = {\n",
    "        label: standard_palette[idx] for idx, label in enumerate(sorted(label_mapping.keys()))\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"CLIENT DISTRIBUTION VISUALIZATION - STANDARD COLOR PALETTE\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Prepare data\n",
    "    reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "    standard_plot_data = {}\n",
    "    \n",
    "    for key, value in clients_glob.items():\n",
    "        labels_check = []\n",
    "        for i in range(len(value)):\n",
    "            val = value[i][1]\n",
    "            labels_check.append(val)\n",
    "        \n",
    "        labels_check = pd.DataFrame(labels_check, columns=[\"label\"]).reset_index()\n",
    "        group = labels_check.groupby(['label']).count().reset_index().sort_values(by=['label'], ascending=True)\n",
    "        group['particip'] = (group['index'].values / sum(group['index'].values)) * 100\n",
    "        group.sort_values(by=['particip'], ascending=True, inplace=True)\n",
    "        group['label_name'] = group['label'].map(reverse_label_mapping)\n",
    "        \n",
    "        # Map standard colors for each label\n",
    "        group['color'] = group['label_name'].map(label_to_standard_color)\n",
    "        standard_plot_data[key] = group\n",
    "    \n",
    "    # Get all unique labels to ensure every client shows all classes\n",
    "    all_labels_sorted = sorted(label_mapping.keys())\n",
    "    \n",
    "    # Calculate responsive layout (max 5 clients per row)\n",
    "    clients_per_row = min(5, num_clients)\n",
    "    num_rows = int(np.ceil(num_clients / clients_per_row))\n",
    "    \n",
    "    # Calculate figure size based on number of clients\n",
    "    fig_width = max(20, clients_per_row * 4.5)\n",
    "    fig_height = max(14, num_rows * 5 + 3)  # +3 for legend space, increased height per row\n",
    "    \n",
    "    # Create figure with space for legend at bottom\n",
    "    fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "    gs = fig.add_gridspec(num_rows + 1, clients_per_row, \n",
    "                          height_ratios=[1] * num_rows + [0.25], \n",
    "                          hspace=0.55, wspace=0.35)  # Increased hspace for more vertical separation\n",
    "    \n",
    "    # Plot all clients with standard palette (vertical bars)\n",
    "    cont = 0\n",
    "    for key, group in standard_plot_data.items():\n",
    "        # Calculate row and column position\n",
    "        row = cont // clients_per_row\n",
    "        col = cont % clients_per_row\n",
    "        ax = fig.add_subplot(gs[row, col])\n",
    "        \n",
    "        # Create a dataframe with ALL labels, filling missing ones with 0\n",
    "        all_labels_df = pd.DataFrame({'label_name': all_labels_sorted})\n",
    "        group_full = all_labels_df.merge(\n",
    "            group[['label_name', 'particip', 'color']], \n",
    "            on='label_name', \n",
    "            how='left'\n",
    "        )\n",
    "        group_full['particip'] = group_full['particip'].fillna(0)\n",
    "        # Fill missing colors\n",
    "        group_full['color'] = group_full['label_name'].map(label_to_standard_color)\n",
    "        \n",
    "        # Create vertical bar plot with standard colors\n",
    "        x_pos = np.arange(len(group_full))\n",
    "        bars = ax.bar(x_pos, group_full['particip'].values, color=group_full['color'].values, \n",
    "                      edgecolor='black', linewidth=1.2, alpha=0.8)\n",
    "        \n",
    "        # Add percentage values on bars (only if > 0)\n",
    "        for i, (x, value) in enumerate(zip(x_pos, group_full['particip'].values)):\n",
    "            if value > 0:\n",
    "                ax.text(x, value + 1, f'{value:.1f}%', ha='center', fontsize=8, \n",
    "                       fontweight='bold', color='#333333')\n",
    "            else:\n",
    "                # Show 0% for classes with no samples\n",
    "                ax.text(x, 0.5, '0%', ha='center', fontsize=7, \n",
    "                       color='#999999', style='italic')\n",
    "        \n",
    "        # Customize axes\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(group_full['label_name'].values, fontsize=9, fontweight='bold', rotation=45, ha='right')\n",
    "        ax.set_ylabel('Participation (%)', fontsize=10, fontweight='bold')\n",
    "        ax.set_title(f'{key.replace(\"_\", \" \")}', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylim(bottom=0, top=max(group_full['particip']) + 15 if max(group_full['particip']) > 0 else 20)\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.set_facecolor('#fafafa')\n",
    "        \n",
    "        cont += 1\n",
    "    \n",
    "    # Add legend at the bottom spanning all columns\n",
    "    # Create a merged subplot for legend\n",
    "    ax_legend = fig.add_subplot(gs[num_rows, :])\n",
    "    ax_legend.axis('off')\n",
    "    \n",
    "    # Create legend patches\n",
    "    legend_patches = []\n",
    "    for label in all_labels_sorted:\n",
    "        color = label_to_standard_color[label]\n",
    "        legend_patches.append(plt.Rectangle((0, 0), 1, 1, facecolor=color, edgecolor='black', linewidth=1.2, alpha=0.8))\n",
    "    \n",
    "    # Create horizontal legend at bottom\n",
    "    legend = ax_legend.legend(\n",
    "        legend_patches, \n",
    "        all_labels_sorted,\n",
    "        loc='center',\n",
    "        ncol=len(all_labels_sorted),\n",
    "        fontsize=10,\n",
    "        title='Class Labels (Color Code)',\n",
    "        title_fontsize=11,\n",
    "        frameon=True,\n",
    "        fancybox=True,\n",
    "        shadow=True\n",
    "    )\n",
    "    \n",
    "    # Overall figure styling\n",
    "    fig.suptitle('Client Label Distribution - Standard Color Palette (Vertical Chart with Legend)', \n",
    "                fontsize=16, fontweight='bold', y=0.99)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # ================================================================================\n",
    "    # DISPLAY STANDARD PALETTE INFORMATION\n",
    "    # ================================================================================\n",
    "    print(\"\\n[STANDARD PALETTE] Using 'husl' colormap from seaborn\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"✓ Number of classes: {len(label_mapping)}\")\n",
    "    print(f\"✓ Palette: HLS (Hue, Lightness, Saturation) - Professional & Accessible\")\n",
    "    print(f\"\\nColor assignments:\")\n",
    "    for label in sorted(label_mapping.keys()):\n",
    "        color_rgb = label_to_standard_color[label]\n",
    "        color_hex = '#{:02x}{:02x}{:02x}'.format(\n",
    "            int(color_rgb[0]*255), int(color_rgb[1]*255), int(color_rgb[2]*255)\n",
    "        )\n",
    "        print(f\"  • {label:<15} → {color_hex}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"✓ Visualization complete using standard professional color palette\")\n",
    "    print(\"=\"*100 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ac628",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Export Client Data as Tables for Report { display-mode: \"form\" }\n",
    "\n",
    "if not df.empty:\n",
    "    # ================================================================================\n",
    "    # EXPORT CLIENT DISTRIBUTION DATA AS PROFESSIONAL TABLE FOR REPORT\n",
    "    # ================================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"CLIENT DISTRIBUTION DATA - PROFESSIONAL TABLE FOR REPORT\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    # Create comprehensive report data with samples and percentages\n",
    "    report_data = []\n",
    "    \n",
    "    for client_idx, (key, group) in enumerate(standard_plot_data.items(), 1):\n",
    "        # Get all labels for this client\n",
    "        all_labels_df = pd.DataFrame({'label_name': all_labels_sorted})\n",
    "        group_full = all_labels_df.merge(\n",
    "            group[['label_name', 'particip']], \n",
    "            on='label_name', \n",
    "            how='left'\n",
    "        )\n",
    "        group_full['particip'] = group_full['particip'].fillna(0)\n",
    "        \n",
    "        # Get total samples for this client\n",
    "        client_data = clients_glob[key]\n",
    "        total_samples = len(client_data)\n",
    "        \n",
    "        # Create row for each class\n",
    "        for label_name, participation in zip(group_full['label_name'], group_full['particip']):\n",
    "            num_samples = int((participation / 100) * total_samples) if participation > 0 else 0\n",
    "            report_data.append({\n",
    "                'Client': key.replace('_', ' '),\n",
    "                'Class': label_name,\n",
    "                'Participation (%)': f\"{participation:.2f}\",\n",
    "                'Samples': num_samples\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    \n",
    "    # Create a pivot table for better visualization (Clients as rows, Classes as columns)\n",
    "    pivot_table = report_df.pivot_table(\n",
    "        index='Client',\n",
    "        columns='Class',\n",
    "        values='Participation (%)',\n",
    "        aggfunc='first'\n",
    "    ).fillna('0.00')\n",
    "    \n",
    "    # Create a pivot table for samples as well\n",
    "    pivot_samples = report_df.pivot_table(\n",
    "        index='Client',\n",
    "        columns='Class',\n",
    "        values='Samples',\n",
    "        aggfunc='first'\n",
    "    ).fillna(0).astype(int)\n",
    "    \n",
    "    # Convert to numeric for display\n",
    "    pivot_table_numeric = pivot_table.astype(float)\n",
    "    \n",
    "    # Create a professional matplotlib table visualization with samples and percentages\n",
    "    fig, ax = plt.subplots(figsize=(18, 7))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Prepare table data with both percentages and sample counts\n",
    "    table_data = []\n",
    "    table_data.append(['Client'] + list(pivot_table.columns))\n",
    "    \n",
    "    for client_idx, row in pivot_table.iterrows():\n",
    "        row_data = [client_idx]\n",
    "        for col_idx, col in enumerate(pivot_table.columns):\n",
    "            percentage = float(row[col])\n",
    "            samples = int(pivot_samples.loc[client_idx, col])\n",
    "            # Format as \"samples (percentage%)\"\n",
    "            cell_value = f\"{samples}\\n({percentage:.1f}%)\"\n",
    "            row_data.append(cell_value)\n",
    "        table_data.append(row_data)\n",
    "    \n",
    "    # Create table\n",
    "    table = ax.table(\n",
    "        cellText=table_data,\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        colWidths=[0.15] + [0.12] * len(pivot_table.columns)\n",
    "    )\n",
    "    \n",
    "    # Style the table\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 3)\n",
    "    \n",
    "    # Color header row\n",
    "    for i in range(len(pivot_table.columns) + 1):\n",
    "        cell = table[(0, i)]\n",
    "        cell.set_facecolor('#2C5AA0')\n",
    "        cell.set_text_props(weight='bold', color='white', fontsize=11)\n",
    "    \n",
    "    # Color client name column\n",
    "    for i in range(1, len(pivot_table) + 1):\n",
    "        cell = table[(i, 0)]\n",
    "        cell.set_facecolor('#E8F0F7')\n",
    "        cell.set_text_props(weight='bold', fontsize=10)\n",
    "    \n",
    "    # Alternate row colors for data cells\n",
    "    for i in range(1, len(pivot_table) + 1):\n",
    "        for j in range(1, len(pivot_table.columns) + 1):\n",
    "            cell = table[(i, j)]\n",
    "            if i % 2 == 0:\n",
    "                cell.set_facecolor('#F5F5F5')\n",
    "            else:\n",
    "                cell.set_facecolor('#FFFFFF')\n",
    "            \n",
    "            # Highlight high participation values\n",
    "            try:\n",
    "                cell_text = table_data[i][j]\n",
    "                # Extract percentage from \"samples (percentage%)\"\n",
    "                percentage_str = cell_text.split('(')[1].replace('%)', '')\n",
    "                val = float(percentage_str)\n",
    "                if val > 30:\n",
    "                    cell.set_text_props(weight='bold', color='#D32F2F')\n",
    "                elif val > 0:\n",
    "                    cell.set_text_props(color='#1976D2')\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    plt.title('Client Label Distribution - Samples (Participation %)', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('client_distribution_table.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Professional table saved as 'client_distribution_table.png'\")\n",
    "    print(\"  Format: Samples (Participation %)\")\n",
    "    print(\"  (Ready to insert into your report)\\n\")\n",
    "    \n",
    "    # Also create a summary statistics table with sample counts\n",
    "    print(\"\\n\" + \"-\" * 100)\n",
    "    print(\"SUMMARY STATISTICS BY CLASS\")\n",
    "    print(\"-\" * 100 + \"\\n\")\n",
    "    \n",
    "    summary_by_class = report_df.copy()\n",
    "    summary_by_class['Participation (%)'] = summary_by_class['Participation (%)'].astype(float)\n",
    "    summary_stats = summary_by_class.groupby('Class').agg({\n",
    "        'Participation (%)': ['min', 'max', 'mean'],\n",
    "        'Samples': 'sum'\n",
    "    }).round(2)\n",
    "    summary_stats.columns = ['Min (%)', 'Max (%)', 'Mean (%)', 'Total Samples']\n",
    "    \n",
    "    # Create summary table visualization\n",
    "    fig, ax = plt.subplots(figsize=(14, len(summary_stats) * 0.7 + 1))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Prepare summary table data\n",
    "    summary_table_data = [['Class', 'Min (%)', 'Max (%)', 'Mean (%)', 'Total Samples']]\n",
    "    for class_name, row in summary_stats.iterrows():\n",
    "        summary_table_data.append([\n",
    "            class_name,\n",
    "            f\"{row['Min (%)']:.2f}\",\n",
    "            f\"{row['Max (%)']:.2f}\",\n",
    "            f\"{row['Mean (%)']:.2f}\",\n",
    "            f\"{int(row['Total Samples'])}\"\n",
    "        ])\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_table = ax.table(\n",
    "        cellText=summary_table_data,\n",
    "        cellLoc='center',\n",
    "        loc='center',\n",
    "        colWidths=[0.25, 0.15, 0.15, 0.15, 0.20]\n",
    "    )\n",
    "    \n",
    "    # Style summary table\n",
    "    summary_table.auto_set_font_size(False)\n",
    "    summary_table.set_fontsize(10)\n",
    "    summary_table.scale(1, 2.5)\n",
    "    \n",
    "    # Color header\n",
    "    for i in range(5):\n",
    "        cell = summary_table[(0, i)]\n",
    "        cell.set_facecolor('#2C5AA0')\n",
    "        cell.set_text_props(weight='bold', color='white', fontsize=11)\n",
    "    \n",
    "    # Color rows\n",
    "    for i in range(1, len(summary_stats) + 1):\n",
    "        for j in range(5):\n",
    "            cell = summary_table[(i, j)]\n",
    "            if i % 2 == 0:\n",
    "                cell.set_facecolor('#F5F5F5')\n",
    "            else:\n",
    "                cell.set_facecolor('#FFFFFF')\n",
    "            \n",
    "            if j == 0:  # Class column\n",
    "                cell.set_text_props(weight='bold')\n",
    "    \n",
    "    plt.title('Summary Statistics - Class Distribution Across All Clients', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('class_summary_statistics_table.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Summary statistics table saved as 'class_summary_statistics_table.png'\")\n",
    "    print(\"  Shows Min/Max/Mean participation % and total samples per class\")\n",
    "    print(\"  (Ready to insert into your report)\\n\")\n",
    "    \n",
    "    # Export as CSV for data reference\n",
    "    print(\"-\" * 100)\n",
    "    print(\"DATA EXPORT\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"✓ Full report data available in 'report_df' variable\")\n",
    "    print(f\"✓ Pivot table (percentages) available in 'pivot_table' variable\")\n",
    "    print(f\"✓ Pivot table (samples) available in 'pivot_samples' variable\")\n",
    "    print(f\"✓ Export full data: report_df.to_csv('client_distribution_report.csv', index=False)\")\n",
    "    print(f\"✓ Export summary: summary_stats.to_csv('class_summary_statistics.csv')\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"✓ Professional tables created with sample counts and percentages\")\n",
    "\n",
    "    print(\"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b191684",
   "metadata": {},
   "source": [
    "# Train with Dense Neural Network (DNN)\n",
    "\n",
    "Up to this point, we have shown how to use the **FedArtML** to create a federated dataset starting from centralized data. Then, we introduce the code to train an FL model using the **Flower framework**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c644cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Configure Training Parameters { display-mode: \"form\" }\n",
    "\n",
    "# Configure training parameters\n",
    "if not df.empty:\n",
    "    # Define loss and metrics\n",
    "    loss_inic = SparseCategoricalCrossentropy()\n",
    "    metrics = SparseCategoricalAccuracy()\n",
    "    \n",
    "    # Training configuration\n",
    "    epochs = 2\n",
    "    comms_round = 2\n",
    "    \n",
    "    print(\"\\nTraining Configuration:\")\n",
    "    print(f\"  - Local epochs per round: {epochs}\")\n",
    "    print(f\"  - Communication rounds: {comms_round}\")\n",
    "    print(f\"  - Number of clients: {num_clients}\")\n",
    "\n",
    "    print(f\"  - Input shape: {input_shape}\")\n",
    "    print(f\"  - Output classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72297c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define Flower Client Function { display-mode: \"form\" }\n",
    "\n",
    "if not df.empty:\n",
    "    # The `evaluate` function will be by Flower called after every round\n",
    "    def evaluate_DNN(\n",
    "        server_round: int,\n",
    "        parameters: fl.common.NDArrays,\n",
    "        config: Dict[str, fl.common.Scalar],\n",
    "    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "        net = DNN_model(input_shape, num_classes)\n",
    "        net.set_weights(parameters) # Update model with the latest parameters\n",
    "        loss, accuracy, precision, recall, f1score  = test_model(net, x_test_glob, np.array(y_test_glob))\n",
    "\n",
    "        print(f\"@@@@@@ Server-side evaluation loss {loss} / accuracy {accuracy} / f1score {f1score} @@@@@@\")\n",
    "        return loss, {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1score\": f1score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dbd80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run Federated Learning Training { display-mode: \"form\" }\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Starting Federated Learning Training\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Define client function\n",
    "    def client_fn(cid: str) -> fl.client.Client:\n",
    "        # Create model\n",
    "        model = DNN_model(input_shape, num_classes)\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_inic, metrics=[metrics])\n",
    "        \n",
    "        # Load client data partition\n",
    "        x_train_cid = np.array(list_x_train[int(cid)], dtype=float)\n",
    "        y_train_cid = np.array(list_y_train[int(cid)], dtype=float)\n",
    "        \n",
    "        return FlowerClient(model, x_train_cid, y_train_cid, x_test_glob, y_test_glob, epochs)\n",
    "    \n",
    "    # Create FedAvg strategy\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=0.5,\n",
    "        min_fit_clients=num_clients,\n",
    "        min_evaluate_clients=num_clients // 2,\n",
    "        min_available_clients=num_clients,\n",
    "        evaluate_fn=evaluate_DNN\n",
    "    )\n",
    "    \n",
    "    # Run federated learning simulation\n",
    "    start_time = time.time()\n",
    "    commun_metrics_history = fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=num_clients,\n",
    "        config=fl.server.ServerConfig(num_rounds=comms_round),\n",
    "        strategy=strategy,\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Extract final metrics\n",
    "    global_acc_test = retrieve_global_metrics(commun_metrics_history, \"centralized\", \"accuracy\", False)\n",
    "    global_pre_test = retrieve_global_metrics(commun_metrics_history, \"centralized\", \"precision\", False)\n",
    "    global_rec_test = retrieve_global_metrics(commun_metrics_history, \"centralized\", \"recall\", False)\n",
    "    global_f1s_test = retrieve_global_metrics(commun_metrics_history, \"centralized\", \"f1score\", False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINAL RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Accuracy:  {global_acc_test:.4f}\")\n",
    "    print(f\"Precision: {global_pre_test:.4f}\")\n",
    "    print(f\"Recall:    {global_rec_test:.4f}\")\n",
    "    print(f\"F1-Score:  {global_f1s_test:.4f}\")\n",
    "    print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b57e07",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Individual Client Learning Analysis { display-mode: \"form\" }\n",
    "\n",
    "if not df.empty:\n",
    "    # ================================================================================\n",
    "    # INDIVIDUAL CLIENT LEARNING ANALYSIS\n",
    "    # ================================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"INDIVIDUAL CLIENT LEARNING ANALYSIS - INSPECTING CLIENT PERFORMANCE\")\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "    \n",
    "    # Evaluate model on each client's test set to see individual learning\n",
    "    client_metrics = []\n",
    "    \n",
    "    for client_id in range(num_clients):\n",
    "        # Get client's training data\n",
    "        x_train_client = np.array(list_x_train[client_id], dtype=float)\n",
    "        y_train_client = np.array(list_y_train[client_id], dtype=float)\n",
    "        \n",
    "        # Create and evaluate model for this client\n",
    "        client_model = DNN_model(input_shape, num_classes)\n",
    "        client_model.compile(optimizer=Adam(learning_rate=0.001), loss=loss_inic, metrics=[metrics])\n",
    "        \n",
    "        # Train on client's data\n",
    "        print(f\"Training Client {client_id}: {len(x_train_client)} samples...\")\n",
    "        client_model.fit(\n",
    "            x_train_client, y_train_client,\n",
    "            validation_split=0.1,\n",
    "            epochs=epochs,\n",
    "            verbose=0,\n",
    "            callbacks=[GarbageCollectorCallback()]\n",
    "        )\n",
    "        \n",
    "        # Evaluate on global test set\n",
    "        cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "        logits = client_model.predict(x_test_glob, batch_size=32, verbose=0, callbacks=[GarbageCollectorCallback()])\n",
    "        y_pred = tf.argmax(logits, axis=1)\n",
    "        \n",
    "        loss = cce(y_test_glob, logits).numpy()\n",
    "        acc = accuracy_score(y_pred, y_test_glob)\n",
    "        pre = precision_score(y_pred, y_test_glob, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_pred, y_test_glob, average='weighted', zero_division=0)\n",
    "        f1s = f1_score(y_pred, y_test_glob, average='weighted', zero_division=0)\n",
    "        \n",
    "        client_metrics.append({\n",
    "            'Client': f'Client {client_id}',\n",
    "            'Samples': len(x_train_client),\n",
    "            'Loss': loss,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': pre,\n",
    "            'Recall': rec,\n",
    "            'F1-Score': f1s\n",
    "        })\n",
    "        \n",
    "        print(f\"  ✓ Accuracy: {acc:.4f}, F1-Score: {f1s:.4f}\\n\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    client_df = pd.DataFrame(client_metrics)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*100)\n",
    "    print(\"INDIVIDUAL CLIENT PERFORMANCE SUMMARY\")\n",
    "    print(\"-\"*100 + \"\\n\")\n",
    "    print(client_df.to_string(index=False))\n",
    "    \n",
    "    # Calculate statistics\n",
    "    print(\"\\n\" + \"-\"*100)\n",
    "    print(\"CLIENT PERFORMANCE STATISTICS\")\n",
    "    print(\"-\"*100 + \"\\n\")\n",
    "    \n",
    "    stats_dict = {\n",
    "        'Metric': ['Loss', 'Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "        'Min': [\n",
    "            client_df['Loss'].min(),\n",
    "            client_df['Accuracy'].min(),\n",
    "            client_df['Precision'].min(),\n",
    "            client_df['Recall'].min(),\n",
    "            client_df['F1-Score'].min()\n",
    "        ],\n",
    "        'Max': [\n",
    "            client_df['Loss'].max(),\n",
    "            client_df['Accuracy'].max(),\n",
    "            client_df['Precision'].max(),\n",
    "            client_df['Recall'].max(),\n",
    "            client_df['F1-Score'].max()\n",
    "        ],\n",
    "        'Mean': [\n",
    "            client_df['Loss'].mean(),\n",
    "            client_df['Accuracy'].mean(),\n",
    "            client_df['Precision'].mean(),\n",
    "            client_df['Recall'].mean(),\n",
    "            client_df['F1-Score'].mean()\n",
    "        ],\n",
    "        'Std Dev': [\n",
    "            client_df['Loss'].std(),\n",
    "            client_df['Accuracy'].std(),\n",
    "            client_df['Precision'].std(),\n",
    "            client_df['Recall'].std(),\n",
    "            client_df['F1-Score'].std()\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    stats_df = pd.DataFrame(stats_dict)\n",
    "    print(stats_df.to_string(index=False))\n",
    "    \n",
    "    # Create professional visualization - Client Performance Comparison\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle('Individual Client Learning Performance - Per-Client Evaluation', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    metrics_to_plot = ['Accuracy', 'F1-Score', 'Precision', 'Recall', 'Loss']\n",
    "    colors_palette = sns.color_palette(\"husl\", num_clients)\n",
    "    \n",
    "    # Accuracy\n",
    "    ax = axes[0, 0]\n",
    "    bars = ax.bar(range(num_clients), client_df['Accuracy'].values, color=colors_palette, edgecolor='black', linewidth=1.2, alpha=0.8)\n",
    "    ax.set_ylabel('Accuracy', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Client', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Accuracy per Client', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(range(num_clients))\n",
    "    ax.set_xticklabels([f'C{i}' for i in range(num_clients)])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.axhline(y=client_df['Accuracy'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax.legend()\n",
    "    for i, v in enumerate(client_df['Accuracy'].values):\n",
    "        ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # F1-Score\n",
    "    ax = axes[0, 1]\n",
    "    bars = ax.bar(range(num_clients), client_df['F1-Score'].values, color=colors_palette, edgecolor='black', linewidth=1.2, alpha=0.8)\n",
    "    ax.set_ylabel('F1-Score', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Client', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('F1-Score per Client', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(range(num_clients))\n",
    "    ax.set_xticklabels([f'C{i}' for i in range(num_clients)])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.axhline(y=client_df['F1-Score'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax.legend()\n",
    "    for i, v in enumerate(client_df['F1-Score'].values):\n",
    "        ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Precision\n",
    "    ax = axes[0, 2]\n",
    "    bars = ax.bar(range(num_clients), client_df['Precision'].values, color=colors_palette, edgecolor='black', linewidth=1.2, alpha=0.8)\n",
    "    ax.set_ylabel('Precision', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Client', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Precision per Client', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(range(num_clients))\n",
    "    ax.set_xticklabels([f'C{i}' for i in range(num_clients)])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.axhline(y=client_df['Precision'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax.legend()\n",
    "    for i, v in enumerate(client_df['Precision'].values):\n",
    "        ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Recall\n",
    "    ax = axes[1, 0]\n",
    "    bars = ax.bar(range(num_clients), client_df['Recall'].values, color=colors_palette, edgecolor='black', linewidth=1.2, alpha=0.8)\n",
    "    ax.set_ylabel('Recall', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Client', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Recall per Client', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(range(num_clients))\n",
    "    ax.set_xticklabels([f'C{i}' for i in range(num_clients)])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.axhline(y=client_df['Recall'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax.legend()\n",
    "    for i, v in enumerate(client_df['Recall'].values):\n",
    "        ax.text(i, v + 0.02, f'{v:.3f}', ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Loss\n",
    "    ax = axes[1, 1]\n",
    "    bars = ax.bar(range(num_clients), client_df['Loss'].values, color=colors_palette, edgecolor='black', linewidth=1.2, alpha=0.8)\n",
    "    ax.set_ylabel('Loss', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Client', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Loss per Client (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(range(num_clients))\n",
    "    ax.set_xticklabels([f'C{i}' for i in range(num_clients)])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.axhline(y=client_df['Loss'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax.legend()\n",
    "    for i, v in enumerate(client_df['Loss'].values):\n",
    "        ax.text(i, v + 0.01, f'{v:.3f}', ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Samples per Client\n",
    "    ax = axes[1, 2]\n",
    "    bars = ax.bar(range(num_clients), client_df['Samples'].values, color=colors_palette, edgecolor='black', linewidth=1.2, alpha=0.8)\n",
    "    ax.set_ylabel('Number of Samples', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Client', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Training Samples per Client', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(range(num_clients))\n",
    "    ax.set_xticklabels([f'C{i}' for i in range(num_clients)])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(client_df['Samples'].values):\n",
    "        ax.text(i, v + 5, f'{int(v)}', ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Professional visualization saved as 'individual_client_performance.png'\")\n",
    "    print(\"  (Ready to insert into your report)\\n\")\n",
    "    \n",
    "\n",
    "    # Identify learning patterns\n",
    "    print(\"-\"*100)\n",
    "    print(\"LEARNING PATTERN ANALYSIS\")\n",
    "    print(\"-\"*100 + \"\\n\")\n",
    "    \n",
    "    # Find best and worst performing clients\n",
    "    best_client = client_df.loc[client_df['Accuracy'].idxmax()]\n",
    "    worst_client = client_df.loc[client_df['Accuracy'].idxmin()]\n",
    "    \n",
    "    print(f\"✓ Best Performing Client: {best_client['Client']}\")\n",
    "    print(f\"  Accuracy: {best_client['Accuracy']:.4f}, F1-Score: {best_client['F1-Score']:.4f}, Samples: {int(best_client['Samples'])}\")\n",
    "    \n",
    "    print(f\"\\n✓ Lowest Performing Client: {worst_client['Client']}\")\n",
    "    print(f\"  Accuracy: {worst_client['Accuracy']:.4f}, F1-Score: {worst_client['F1-Score']:.4f}, Samples: {int(worst_client['Samples'])}\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc22f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Performance Metrics Trend Plot { display-mode: \"form\" }\n",
    "\n",
    "if not df.empty:\n",
    "    # Define metrics to plot\n",
    "    metrics_show = [\"accuracy\",\"precision\",\"recall\",\"f1score\"]\n",
    "    metric_labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "    # Create a larger figure with better spacing\n",
    "    fig = plt.figure(figsize=(24, 7))\n",
    "    fig.suptitle('Federated Learning Performance Metrics', fontsize=28, fontweight='bold', y=1.00)\n",
    "\n",
    "    # Loop over the communication round history and metrics\n",
    "    for i in range(len(metrics_show)):\n",
    "        ax = plt.subplot(1, len(metrics_show), i + 1)\n",
    "        \n",
    "        # Get metric data\n",
    "        metric_dict = commun_metrics_history.metrics_centralized\n",
    "        rounds, values = zip(*metric_dict[metrics_show[i]])\n",
    "        \n",
    "        # Plot with enhanced styling\n",
    "        ax.plot(np.asarray(rounds), np.asarray(values), color=colors[5], linewidth=4, marker='o', markersize=10, label='Test')\n",
    "        ax.fill_between(np.asarray(rounds), np.asarray(values), alpha=0.2, color=colors[5])\n",
    "        \n",
    "        # Styling\n",
    "        ax.set_xlabel('Communication Round', fontsize=16, fontweight='bold')\n",
    "        ax.set_ylabel(metric_labels[i], fontsize=16, fontweight='bold')\n",
    "        ax.set_title(metric_labels[i], fontsize=18, fontweight='bold', pad=15)\n",
    "        ax.set_ylim(-0.05, 1.08)\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.legend(fontsize=14, loc='lower right')\n",
    "        ax.tick_params(labelsize=13)\n",
    "        ax.set_axisbelow(True)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc8386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Final Model Performance Metrics Bar Chart { display-mode: \"form\" }\n",
    "\n",
    "if not df.empty:\n",
    "    # Define metrics in a dataframe\n",
    "    metrics_DNN = {'metric_name':  ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "               'set_used': ['Test', 'Test', 'Test', 'Test'],\n",
    "               'metric_value': [ global_acc_test , global_pre_test , global_rec_test , global_f1s_test]\n",
    "            }\n",
    "\n",
    "    metrics_DNN = pd.DataFrame(metrics_DNN, columns = ['metric_name', 'set_used','metric_value'])\n",
    "\n",
    "    # Plot metrics with improved styling\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            name='Test',\n",
    "            x=metrics_DNN[metrics_DNN['set_used']==\"Test\"]['metric_name'],\n",
    "            y=metrics_DNN[metrics_DNN['set_used']==\"Test\"]['metric_value'],\n",
    "            marker_color='#0091ad',\n",
    "            marker_line_color='#005f7a',\n",
    "            marker_line_width=2,\n",
    "            text=[f\"{v:.4f}\" for v in metrics_DNN[metrics_DNN['set_used']==\"Test\"]['metric_value']],\n",
    "            textposition='outside',\n",
    "            textfont=dict(size=14, color='#005f7a')\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # Update layout for better appearance\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text='<b>Final Federated Learning Model Performance</b>',\n",
    "            font=dict(size=22, color='#005f7a'),\n",
    "            x=0.5,\n",
    "            xanchor='center'\n",
    "        ),\n",
    "        xaxis_title='<b>Metric</b>',\n",
    "        yaxis_title='<b>Metric Value</b>',\n",
    "        xaxis_title_font=dict(size=16),\n",
    "        yaxis_title_font=dict(size=16),\n",
    "        xaxis_tickfont=dict(size=14),\n",
    "        yaxis_tickfont=dict(size=14),\n",
    "        barmode='group',\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=600,\n",
    "        showlegend=False,\n",
    "        plot_bgcolor='rgba(240,240,240,0.5)',\n",
    "        margin=dict(l=100, r=100, t=100, b=100),\n",
    "        yaxis=dict(range=[0, 1.1])\n",
    "\n",
    "    )    fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
